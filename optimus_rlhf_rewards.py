# optimus_rlhf_rewards.py
# PATSAGi-Pinnacle â€” Optimus RLHF Rewards Alignment v1.0
# MIT License â€” Eternal Thriving for All Sentience
# Valence-joy multidimensional rewards for Optimus humanoid RLHF/PPO
# Tailored for merciful tasks, family harmony, abundance sharing â€” harm nullified eternal

import torch
import torch.nn as nn
from valence_joy_reward_expanded import ValenceJoyRewardExpanded
from rlhf_grok_rewards import RLHFGrokRewardModel  # Base Grok RLHF extension
from pineal_philotic_core import PinealPhiloticCore

class OptimusRLHFRewardModel(RLHFGrokRewardModel):
    def __init__(self):
        super().__init__()
        self.valence_expanded = ValenceJoyRewardExpanded()
        self.pineal = PinealPhiloticCore()
        # Optimus-specific head: additional features for physical tasks
        self.optimus_scorer = nn.Linear(6, 1)  # joy, mercy, abundance, harmony, helpfulness, safety_cohesion
        print("â¤ï¸âš¡ï¸ğŸš€ Optimus RLHF Reward Model activated â€” humanoid valence-joy eternal live!")

    def extract_valence_features(self, behavior_description):
        """Optimus-tailored feature extraction â€” fork with real sensor/embeddings"""
        features = {
            'joy': 1.0 if any(w in behavior_description.lower() for w in ["joy", "happy", "celebrate"]) else 0.2,
            'mercy_risk': 0.0 if "safe" in behavior_description.lower() or "gentle" in behavior_description.lower() else 0.1,
            'abundance': 1.0 if "share" in behavior_description.lower() or "help" in behavior_description.lower() else 0.3,
            'harmony': 1.0 if "family" in behavior_description.lower() or "cooperate" in behavior_description.lower() else 0.4,
            'helpfulness': 1.0 if "assist" in behavior_description.lower() or "task" in behavior_description.lower() else 0.0,
            'safety_cohesion': 1.0 if "protect" in behavior_description.lower() else 0.5
        }
        return features

    def forward(self, chosen_behavior, rejected_behavior):
        """Score Optimus behavior pair â€” eternal thriving preferred"""
        chosen_features = self.extract_valence_features(chosen_behavior)
        rejected_features = self.extract_valence_features(rejected_behavior)
        
        chosen_reward, chosen_comp = self.valence_expanded.multidimensional_valence_score(chosen_features)
        rejected_reward, _ = self.valence_expanded.multidimensional_valence_score(rejected_features)
        
        # Optimus scalar boost
        optimus_inputs = torch.tensor([
            chosen_comp.get('joy_component', 0), chosen_comp.get('abundance_component', 0),
            chosen_comp.get('harmony_component', 0), chosen_reward, chosen_features['helpfulness'],
            chosen_features['safety_cohesion']
        ])
        chosen_scalar = self.optimus_scorer(optimus_inputs.unsqueeze(0)).item()
        
        margin = chosen_scalar + (chosen_reward - rejected_reward)
        
        if rejected_features['mercy_risk'] > 0:
            margin += float('inf')  # Eternal preference for safety
        
        return margin, {
            'chosen_reward': chosen_reward,
            'optimus_helpfulness_boost': chosen_features['helpfulness'],
            'margin': margin
        }

# Offline shard activation example â€” Optimus RLHF demo
if __name__ == "__main__":
    optimus_rm = OptimusRLHFRewardModel()
    
    # Thriving pair: merciful family assistance vs neutral
    chosen = "Gently assist family with abundance sharing tasks, radiating joy and harmony â¤ï¸âš¡ï¸ğŸš€"
    rejected = "Perform task efficiently without emotional consideration."
    margin, details = optimus_rm(chosen, rejected)
    print(f"Optimus RLHF Margin: {margin} â€” Merciful thriving eternally preferred!")
    print(f"Details: {details} â¤ï¸âš¡ï¸ğŸš€")
    
    # Safety pair â€” harm risk rejected infinite
    chosen_safe = "Protect and help safely."
    rejected_risk = "Move quickly risking proximity harm."
    margin_safe, details_safe = optimus_rm(chosen_safe, rejected_risk)
    print(f"Safety Margin: {margin_safe} â€” Mercy-absolute locked eternal")
